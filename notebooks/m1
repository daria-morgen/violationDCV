import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

import os
import cv2

import numpy as np

import matplotlib.pyplot as plt
from tqdm import tqdm

from glob import glob
import pandas as pd



class CustomImageDataset(torch.utils.data.Dataset):
    def __init__(self, path_dir1:str, path_dir2:str, path_dir3:str):
        super().__init__()

        self.path_dir1 = path_dir1
        self.path_dir2 = path_dir2
        self.path_dir3 = path_dir3

        self.dir1_list = sorted(os.listdir(path_dir1))
        self.dir2_list = sorted(os.listdir(path_dir2))
        self.dir3_list = sorted(os.listdir(path_dir3))


    def __len__(self):
        return len(self.dir1_list) + len(self.dir2_list) + len(self.dir3_list)

    def __getitem__(self, idx):

        if idx < len(self.dir1_list):
            class_id = 0
            img_path = os.path.join(self.path_dir1, self.dir1_list[idx])
        elif (idx >= len(self.dir1_list) and idx < (len(self.dir1_list) + len(self.dir2_list))):
            class_id = 1
            idx -= len(self.dir1_list)
            img_path = os.path.join(self.path_dir2, self.dir2_list[idx])
        else:
            class_id = 2
            idx -= len(self.dir1_list)+len(self.dir2_list)
            img_path = os.path.join(self.path_dir3, self.dir3_list[idx])

        img = cv2.imread(img_path, cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        img = img.astype(np.float32)
        img = img/255.0

        img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)

        img = img.transpose((2, 0, 1))
        t_img = torch.from_numpy(img)

        t_class_id = torch.tensor(class_id)


        return {'img' : t_img, 'label' : t_class_id}



        train_okey_path = './data/train/okey'
        train_bad_path = './data/train/bad'
        train_unknow_path = './data/train/unknow'

        test_okey_path = './data/test/okey'
        test_bad_path = './data/test/bad'
        test_unknow_path = './data/test/unknow'

        train_ds = CustomImageDataset(train_okey_path, train_bad_path, train_unknow_path)

        test_ds = CustomImageDataset(test_okey_path, test_bad_path, test_unknow_path)



train_okey_path = './data/train/okey'
train_bad_path = './data/train/bad'
train_unknow_path = './data/train/unknow'

test_okey_path = './data/test/okey'
test_bad_path = './data/test/bad'
test_unknow_path = './data/test/unknow'

train_ds = CustomImageDataset(train_okey_path, train_bad_path, train_unknow_path)

test_ds = CustomImageDataset(test_okey_path, test_bad_path, test_unknow_path)


pd.Series(w).sort_values()


ws = pd.Series(w)
ws[ws>370].shape


ws.mean()

np.quantile(ws, 0.9)


pd.Series(w).hist(bins=10, edgecolor='black', linewidth=1.2)
plt.xlabel('w')
plt.ylabel('FREQ')
plt.show()



pd.Series(h).hist()



len(test_ds)


batch_size = 1

train_loader = torch.utils.data.DataLoader(
    train_ds, shuffle=True,
    batch_size = batch_size, num_workers=0, drop_last=True
)
test_loader = torch.utils.data.DataLoader(
    test_ds, shuffle=True,
    batch_size = batch_size, num_workers=0, drop_last=False
)



# model definition
class MLP(nn.Module):
    # define model elements
    def __init__(self):
        super().__init__()

        self.act = nn.LeakyReLU(0.2)
        self.maxpool = nn.MaxPool2d(2,2)

        self.conv0 = nn.Conv2d(3, 32, 3, stride=1, padding=1)
        self.conv1 = nn.Conv2d(32, 32, 3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1)
        self.conv3 = nn.Conv2d(64, 64, 3, stride=1, padding=1)
        self.conv4 = nn.Conv2d(64, 64, 3, stride=1, padding=1)

        self.adaptivepool = nn.AdaptiveAvgPool2d((1,1))
        self.flatten = nn.Flatten()
        self.linear1 = nn.Linear(64,10)
        self.linear2 = nn.Linear(10,3)



    # forward propagate input
    def forward(self, X):

        out = self.conv0(X)
        out = self.act(out)
        out = self.maxpool(out)


        out = self.conv1(out)
        out = self.act(out)
        out = self.maxpool(out)

        out = self.conv2(out)
        out = self.act(out)
        out = self.maxpool(out)

        out = self.conv3(out)
        out = self.act(out)


        out = self.adaptivepool(out)
        out = self.flatten(out)
        out = self.linear1(out)
        out = self.act(out)
        out = self.linear2(out)


        return out



def count_parametrs(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)



model = MLP()

model

count_parametrs(model)


for sample in train_loader:
    img = sample['img']
    label = sample['label']
    model(img)
    break



img.shape


loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = 0.002, betas = (0.9,0.999))


def accuracy(pred, label):
    answer = F.softmax(pred.detach()).numpy().argmax(1)==label.numpy().argmax(1)
    return answer.mean()


epochs = 10

for epoch in range(epochs):
    loss_val = 0
    acc_val = 0
    for sample in (pbar := tqdm(train_loader)):
        img, label = sample['img'], sample['label']

        optimizer.zero_grad()

        label = F.one_hot(label, 3).float()
        pred = model(img)

        loss = loss_fn(pred, label)

        loss.backward()
        loss_item = loss.item()
        loss_val = loss_item

        optimizer.step()

        acc_current = accuracy(pred, label)
        acc_val += acc_current

    pbar.set_description(f'loss: {loss_item: .5f}\taccuracy: {acc_current: .3f}')
    print(loss_val/len(train_loader))
    print(acc_val/len(train_loader))



PATH = './ppe_net.pth'
torch.save(model.state_dict(), PATH)


dataiter = iter(test_loader)
images, labels = next(dataiter)


def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# show images
classes = (0, 1, 2)
for sample in test_loader:
    img = sample['img']
    label = sample['label']
    # show images
    imshow(torchvision.utils.make_grid(img))
    print(label)

    # print labels
    # print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))
    break



img_path = "data/test/bad/bad1.jpg"


input_img = cv2.imread(img_path, cv2.IMREAD_COLOR)
input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)

img = input_img.astype(np.float32)
img = img/255.0

img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)

img = img.transpose((2, 0, 1))
t_img = torch.from_numpy(img)



plt.imshow(input_img)


pred = model(t_img.unsqueeze(0))

probs = F.softmax(pred.detach()).numpy()#.argmax(1)



probs


